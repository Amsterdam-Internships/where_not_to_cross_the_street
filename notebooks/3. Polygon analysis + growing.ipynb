{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1717435067323
        }
      },
      "outputs": [],
      "source": [
        "import math\n",
        "from shapely.geometry import Polygon, Point, MultiPolygon, LineString\n",
        "import geopandas as gpd\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Notebook overview\n",
        "\n",
        "In this notebook we analyze the processed clusters based on their shape and size. We check for two requirements:\n",
        "1. Is the cluster a rectangle?\n",
        "2. Do the sides match the lengths of a crosswalk stripe?\n",
        "\n",
        "Once we have checked each cluster, we merge the ones that stem from the same original polygon into one crosswalk polygon.\n",
        "\n",
        "Additionally, we take the two outer stripes of each crosswalk polygon and extend these to create a polygon on each end of the crosswalk. These polygons will be run through notebook 2 in order to check if any crosswalk stripes were missed.\n",
        "\n",
        "**Input**: cluster dictionary as created in notebook 2.\n",
        "\n",
        "**Output**: Shapely file with extended polygons that serve as input for the next step.\n",
        "\n",
        "**Previous notebook**: 2. Point cloud processing, matching and cluster growing.\n",
        "\n",
        "**Next notebook**: 2. Point cloud processing, matching and cluster growing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Settings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "CRS = 'epsg:28992'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Loading data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1717435071824
        }
      },
      "outputs": [],
      "source": [
        "# Load cluster dictionary\n",
        "path = \"../data/output/cluster dict.pkl\"\n",
        "\n",
        "with open(path, 'rb') as file:\n",
        "    clusters = pickle.load(file)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Plotting function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "gather": {
          "logged": 1717435100162
        }
      },
      "outputs": [],
      "source": [
        "# Function to plot PC polygon (can be used if desired, not necessary)\n",
        "def plot_PC_2D(PC_pol_dict, coords, intensity):\n",
        "    x = PC_pol_dict[coords][:, 0]\n",
        "    y = PC_pol_dict[coords][:, 1]\n",
        "    plt.figure()\n",
        "    plt.scatter(x, y, c=PC_pol_dict[intensity], cmap='viridis', vmin=0)\n",
        "    plt.colorbar(label='Reflective index')  # Add colorbar to show gradient values\n",
        "    plt.xlabel('X')\n",
        "    plt.ylabel('Y')\n",
        "\n",
        "    plt.grid(True)\n",
        "    plt.axis('equal')\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Filtering polygons"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "gather": {
          "logged": 1717435125324
        }
      },
      "outputs": [],
      "source": [
        "# Create Shapely polygons out of the PC polygons\n",
        "\n",
        "# Loop over each cluster group\n",
        "for cluster_group in clusters:\n",
        "\n",
        "    # Loop over each cluster\n",
        "    for cluster in cluster_group:\n",
        "\n",
        "        pols = []\n",
        "\n",
        "        # Loop over coordinates in cluster and buffer them to create small polygons\n",
        "        for coor in cluster['clean_coords']:\n",
        "            temp_point = Point(coor[0], coor[1])\n",
        "            buff_point = temp_point.buffer(0.08)\n",
        "            pols.append(buff_point)\n",
        "        \n",
        "        # Merge all small coordinate polygons together into one Shapely polgyon\n",
        "        multi_pol = MultiPolygon(pols)\n",
        "        cluster['Multi Polygon'] = multi_pol\n",
        "        cluster['Polygon'] = multi_pol.convex_hull"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "gather": {
          "logged": 1717435125448
        }
      },
      "outputs": [],
      "source": [
        "# Function to plot the polygons\n",
        "def plot_polygon(polygon):\n",
        "    # Extract polygon coordinates\n",
        "    x_coords, y_coords = polygon.exterior.xy\n",
        "    \n",
        "    # Calculate aspect ratio based on the range of x and y coordinates\n",
        "    x_range = max(x_coords) - min(x_coords)\n",
        "    y_range = max(y_coords) - min(y_coords)\n",
        "    aspect_ratio = y_range / x_range\n",
        "    \n",
        "    # Create the plot with the calculated aspect ratio\n",
        "    fig, ax = plt.subplots(figsize=(5, 5 * aspect_ratio))  # Adjust the figsize as needed\n",
        "    ax.set_aspect('equal')  # Ensure equal aspect ratio\n",
        "    \n",
        "    # Plot the polygon\n",
        "    ax.plot(x_coords, y_coords, color='blue')\n",
        "    \n",
        "    # Show the plot\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "gather": {
          "logged": 1717435125776
        }
      },
      "outputs": [],
      "source": [
        "# Function to check if a polygon is a crosswalk stripe\n",
        "def is_rectangle(polygon):\n",
        "\n",
        "    # We first check if the minimum rotated rectangle overlaps for at least 90% with the original polygon\n",
        "    # This filters out shapes that are not square/rectangular\n",
        "    min_rect = polygon.minimum_rotated_rectangle\n",
        "    \n",
        "    area = polygon.area/min_rect.area\n",
        "\n",
        "    if area > .90:\n",
        "        area_bool = True\n",
        "        \n",
        "    else:\n",
        "        area_bool = False\n",
        "\n",
        "    # We then check the lengths of the vertices of the polygon to see if they resemble a crosswalk stripe\n",
        "    if area_bool == True:\n",
        "        coords = min_rect.boundary.coords\n",
        "        \n",
        "        linestrings = [LineString(coords[k:k+2]) for k in range(len(coords) - 1)]\n",
        "\n",
        "        lengths = []\n",
        "\n",
        "        for line in linestrings:\n",
        "            lengths.append(line.length)\n",
        "        \n",
        "        # Define the conditions\n",
        "        condition1 = sum(1.4 <= length <= 7 for length in lengths)\n",
        "        condition2 = sum(0.6 <= length <= 0.8 for length in lengths)\n",
        "\n",
        "        # Check if the conditions are met\n",
        "        if not (condition1 == 2 and condition2 == 2):\n",
        "            area_bool = False\n",
        "\n",
        "    \n",
        "    return area, area_bool\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "gather": {
          "logged": 1717435125906
        }
      },
      "outputs": [],
      "source": [
        "# Function to merge rectangular clusters of one crosswalk polygon\n",
        "def merge_clusters(clusters):\n",
        "\n",
        "    polygons = []\n",
        "    clean_coords = []\n",
        "    clean_intensity = []\n",
        "    coords = []\n",
        "    intensity = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        len_coords = len(cluster['clean_coords'])\n",
        "\n",
        "        break_triggered = False\n",
        "        for item in clean_coords:\n",
        "            if len(item) == len_coords:\n",
        "                break_triggered = True\n",
        "                break  # Exit the inner loop if a match is found\n",
        "\n",
        "        if break_triggered:\n",
        "            continue  # Skip the rest of the outer loop for this cluster\n",
        "\n",
        "        # Only executed if no match is found\n",
        "        polygons.append(cluster['Polygon'])\n",
        "        coords.append(cluster['coordinates'])\n",
        "        intensity.append(cluster['intensity'])\n",
        "        clean_coords.append(cluster['clean_coords'])\n",
        "        clean_intensity.append(cluster['clean_intensity'])\n",
        "    \n",
        "    PC_coords = np.concatenate(coords, axis=0)\n",
        "    PC_intensity = np.concatenate(intensity, axis=0)\n",
        "    PC_coords_clean = np.concatenate(clean_coords, axis=0)\n",
        "    PC_intensity_clean = np.concatenate(clean_intensity, axis=0)\n",
        "    \n",
        "    multi_pol = MultiPolygon(polygons)\n",
        "    \n",
        "    pol = multi_pol.convex_hull\n",
        "\n",
        "    pol_dict = {'CW_index': clusters[0]['CW_index'], 'coordinates': PC_coords, 'intensity': PC_intensity, 'clean_coords': PC_coords_clean, 'clean_intensity': PC_intensity_clean, 'polygon': pol}\n",
        "\n",
        "    return pol_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to filter out duplicates in the rectangle cluster dictionary\n",
        "def filter_duplicates(data):\n",
        "    seen_lengths = set()\n",
        "    unique_items = []\n",
        "    \n",
        "    for item in data:\n",
        "        length = len(item['clean_coords'])\n",
        "        if length not in seen_lengths:\n",
        "            seen_lengths.add(length)\n",
        "            unique_items.append(item)\n",
        "    \n",
        "    return unique_items"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "gather": {
          "logged": 1717435126067
        }
      },
      "outputs": [],
      "source": [
        "# Function to check if the polygons are rectangles \n",
        "def check_rectangles(clusters):\n",
        "    # Initialize list of rectangular clusters\n",
        "    rect_clusters = []\n",
        "\n",
        "    # Initialize list of final polygons\n",
        "    polygon_dict = []\n",
        "\n",
        "    for i in range(0, len(clusters)):\n",
        "\n",
        "        merged = merge_clusters(clusters[i])\n",
        "\n",
        "        # Initialize list to keep track of rectangular cluster dictionaries in a crosswalk\n",
        "        cluster_list = []\n",
        "\n",
        "        for cluster in clusters[i]:\n",
        "            \n",
        "            area, rect_bool = is_rectangle(cluster['Polygon'])\n",
        "            \n",
        "            if rect_bool is True:\n",
        "\n",
        "                # Append cluster to list of rectangular clusters of the crosswalk\n",
        "                cluster_list.append(cluster)        \n",
        "\n",
        "        if len(cluster_list) > 0:\n",
        "\n",
        "            rect_clusters.append(filter_duplicates(cluster_list))\n",
        "\n",
        "            # Merge clusters\n",
        "            pol = merge_clusters(cluster_list)\n",
        "\n",
        "            # Add final polygon to polygon dict\n",
        "            polygon_dict.append(pol)\n",
        "\n",
        "    return polygon_dict, rect_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "polygon_dict, rect_clusters = check_rectangles(clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save final polygons as gdf\n",
        "path = \"../data/output/filtered polygons.shp\"\n",
        "polygons_df = pd.DataFrame.from_records(polygon_dict)\n",
        "polygons_df = polygons_df.drop(columns=['CW_index', 'coordinates', 'intensity', 'clean_coords', 'clean_intensity'])\n",
        "polygons_gdf = gpd.GeoDataFrame(polygons_df, crs='epsg:28992', geometry='polygon')\n",
        "polygons_gdf.to_file(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to compute the eucledian distance between two points\n",
        "def euclidean_distance(p1, p2):\n",
        "    return np.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to get the outer clusters of a group of clusters that stem from the same polygon\n",
        "def get_outer_clusters(clusters):\n",
        "    if len(clusters) == 1:\n",
        "        return [clusters[0], clusters[0]]\n",
        "    \n",
        "    centroid_points = []\n",
        "\n",
        "    for cluster in clusters:\n",
        "        centroid = np.array(cluster['Polygon'].centroid.coords[0])\n",
        "        centroid_point = Point(centroid[0], centroid[1])\n",
        "        centroid_points.append(centroid_point)\n",
        "    point_coords = np.array([(point.x, point.y) for point in centroid_points])\n",
        "\n",
        "    max_distance = 0\n",
        "    outer_points = (None, None)\n",
        "\n",
        "    for i in range(len(point_coords)):\n",
        "        for j in range(i + 1, len(point_coords)):\n",
        "            dist = euclidean_distance(point_coords[i], point_coords[j])\n",
        "            if dist > max_distance:\n",
        "                max_distance = dist\n",
        "                outer_points = (point_coords[i], point_coords[j])\n",
        "\n",
        "    # Retrieve original cluster\n",
        "    # Iterate through the clusters\n",
        "    outer_clusters = []\n",
        "\n",
        "    # Iterate through the clusters\n",
        "    for cluster in clusters:\n",
        "        # Extract the centroid of the cluster\n",
        "        centroid = np.array(cluster['Polygon'].centroid.coords[0])\n",
        "        \n",
        "        # Create a Point object from the centroid coordinates\n",
        "        centroid_point = Point(centroid[0], centroid[1])\n",
        "        \n",
        "        # Check if the centroid matches either of the outer points\n",
        "        if np.array_equal(centroid_point.coords[0], outer_points[0]): \n",
        "            outer_clusters.append(cluster)\n",
        "\n",
        "        elif np.array_equal(centroid_point.coords[0], outer_points[1]):\n",
        "            outer_clusters.append(cluster)\n",
        "    \n",
        "    centroids = []\n",
        "    for cluster in outer_clusters:\n",
        "        centroid = cluster['Polygon'].centroid.x\n",
        "        centroids.append(centroid)\n",
        "    \n",
        "    if len(centroids) > 1:\n",
        "        if centroids[1] < centroids[0]:\n",
        "            outer_clusters = [outer_clusters[1], outer_clusters[0]]\n",
        "\n",
        "    return outer_clusters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Get the outer clusters of each group of clusters\n",
        "outer_cluster_dict = []\n",
        "\n",
        "for clusters in rect_clusters:\n",
        "    outer_clusters = get_outer_clusters(clusters)\n",
        "    outer_cluster_dict.append(outer_clusters)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Function to extend a polygon to either the left or the right\n",
        "def extend_polygon(outer_clusters, direction):\n",
        "    # Set the outer cluster based on direction\n",
        "    if direction == 'right':\n",
        "        outer_cluster = outer_clusters[1]\n",
        "    if direction == 'left':\n",
        "        outer_cluster = outer_clusters[0]\n",
        "\n",
        "    # Get minimum rectangle\n",
        "    min_rect = outer_cluster['Polygon'].minimum_rotated_rectangle\n",
        "\n",
        "    # Extract the coordinates of the rectangle\n",
        "    rect_coords = list(min_rect.exterior.coords)\n",
        "\n",
        "    # Remove the duplicate last point\n",
        "    rect_coords = rect_coords[:-1]\n",
        "\n",
        "    # Calculate the lengths of the sides\n",
        "    sides = []\n",
        "    for i in range(len(rect_coords)):\n",
        "        p1 = rect_coords[i]\n",
        "        p2 = rect_coords[(i + 1) % len(rect_coords)]\n",
        "        side = LineString([p1, p2])\n",
        "        sides.append((side.length, side))\n",
        "\n",
        "    # Sort sides by length\n",
        "    sides.sort(key=lambda x: x[0])\n",
        "\n",
        "    # Short sides are the first two in the sorted list\n",
        "    short_sides = sides[:2]\n",
        "\n",
        "    # Extract start and end points\n",
        "    if short_sides[0][1].coords[0][0] < short_sides[0][1].coords[1][0]:\n",
        "        start_point1 = short_sides[0][1].coords[0]\n",
        "        end_point1 = short_sides[0][1].coords[1]\n",
        "    else:\n",
        "        start_point1 = short_sides[0][1].coords[1]\n",
        "        end_point1 = short_sides[0][1].coords[0]\n",
        "\n",
        "    if short_sides[1][1].coords[0][0] < short_sides[1][1].coords[1][0]:\n",
        "        start_point2 = short_sides[1][1].coords[0]\n",
        "        end_point2 = short_sides[1][1].coords[1]\n",
        "    else:\n",
        "        start_point2 = short_sides[1][1].coords[1]\n",
        "        end_point2 = short_sides[1][1].coords[0]\n",
        "\n",
        "    # Calculate the direction vector\n",
        "    direction_vector = (end_point1[0] - start_point1[0], end_point1[1] - start_point1[1])\n",
        "    # Calculate the length of the direction vector\n",
        "    length = math.sqrt(direction_vector[0]**2 + direction_vector[1]**2)\n",
        "\n",
        "    # Normalize the direction vector\n",
        "    normalized_direction = (direction_vector[0] / length, direction_vector[1] / length)\n",
        "\n",
        "    # Define the extension length\n",
        "    extension_length = 2  # for example, extend by 1 unit\n",
        "\n",
        "    if direction == 'right':\n",
        "        # Calculate the new end points for right direction\n",
        "        new_end_point1 = (\n",
        "            end_point1[0] + normalized_direction[0] * extension_length,\n",
        "            end_point1[1] + normalized_direction[1] * extension_length\n",
        "        )\n",
        "\n",
        "        new_end_point2 = (\n",
        "            end_point2[0] + normalized_direction[0] * extension_length,\n",
        "            end_point2[1] + normalized_direction[1] * extension_length\n",
        "        )\n",
        "\n",
        "        new_start_point1 = end_point1\n",
        "        new_start_point2 = end_point2\n",
        "    else:\n",
        "        # Calculate the new start points for left direction\n",
        "        new_start_point1 = (\n",
        "            start_point1[0] - normalized_direction[0] * extension_length,\n",
        "            start_point1[1] - normalized_direction[1] * extension_length\n",
        "        )\n",
        "\n",
        "        new_start_point2 = (\n",
        "            start_point2[0] - normalized_direction[0] * extension_length,\n",
        "            start_point2[1] - normalized_direction[1] * extension_length\n",
        "        )\n",
        "\n",
        "        new_end_point1 = start_point1\n",
        "        new_end_point2 = start_point2\n",
        "\n",
        "    new_pol = [new_start_point1, new_start_point2, new_end_point1, new_end_point2]\n",
        "    new_pol = Polygon(new_pol).minimum_rotated_rectangle\n",
        "\n",
        "    return new_pol\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "extended_polygons = []\n",
        "\n",
        "for clusters in outer_cluster_dict:\n",
        "    if len(clusters) > 1:\n",
        "        # Extend polygons and plot them in green\n",
        "        left_extension = extend_polygon(clusters, \"left\")\n",
        "        right_extension = extend_polygon(clusters, \"right\")\n",
        "        extended_polygons.append(left_extension)\n",
        "        extended_polygons.append(right_extension)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "extended_df = pd.DataFrame({'geometry': extended_polygons})\n",
        "extended_gdf = gpd.GeoDataFrame(extended_df, geometry='geometry')\n",
        "extended_gdf = extended_gdf.set_crs(CRS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save extended outer clusters \n",
        "path = \"../data/output/extended polygons.shp\"\n",
        "\n",
        "extended_gdf.to_file(path)"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "tile2net"
    },
    "kernelspec": {
      "display_name": "envLeah",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
